<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Harvey Barnhard">

    <title>Harvey - Blog Post</title>

    <!-- Bootstrap Core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="../css/clean-blog.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <script src="https://kit.fontawesome.com/b89efab99d.js" crossorigin="anonymous"></script>
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- LaTeX Rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- code block Rendering -->
    <link rel="stylesheet" href="../css/androidstudio.css">
    <script src="../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- favicon -->
    <link rel="shortcut icon" type="image/x-icon" href="../img/favicon.ico">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom">
      <div class="container-fluid">
        <div class="navbar-header page-scroll">
          <button type="button" class="navbar-toggle x collapsed" data-toggle="collapse" data-target="#navbar-collapse-x">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="navbar-collapse-x">
          <ul class="nav navbar-nav navbar-right">
            <li>
              <a href="../projects.html">projects</a>
            </li>
            <li>
              <a href="../about.html">about</a>
            </li>
          </ul>
        </div>
        <!-- /.navbar-collapse -->
      </div>
      <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('../img/looperr-preview.png')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="page-heading">
                        <h1>Evaluating Prediction Error</h1>
                        <h2 class="subheading"></h2>
                    </div>
                </div>
            </div>
        </div>
    </header>
    <!-- main text -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
              <h1>The Astounding Formula</h1>
              <h1> Linear Smoothers</h1>
              <p>
                A linear smoother is a transformation of the observed data
                \(X\) and \(Y\) that \(\hat{Y}\)
                can be expressed as a linear combination of \(Y\):
                \[ \hat{Y} = LY\]
                where \(L\) is a \(n \times n\) matrix that
                takes the
                following form as a function of \(X\):
                \[
                  L =
                  \begin{bmatrix}
                  \ell(X_1)^\top\\
                  \vdots \\
                  \ell(X_n)^\top
                  \end{bmatrix}
                  =
                  \begin{bmatrix}
                    \ell_1(x_1) & \ell_2(x_1) & \cdots & \ell_n(x_1)\\
                    \ell_1(x_2) & \ell_2(x_2) & \cdots & \ell_n(x_2)\\
                    \vdots & \vdots & \ddots & \vdots \\
                    \ell_1(x_n) & \ell_2(x_n) & \cdots & \ell_n(x_n)
                  \end{bmatrix}
                \]
                and \(x_i\) is the \(i\)th row of the \(n\times p\)
                data matrix \(X\).

                Letting \(L_{ii}=\ell_1(X_1)\) be the \(i\)th diagonal element of
                \(L\), we can express the LOOCV score as
                \[
                  \text{LOOCV} = \sum_{i=1}^n\left(\frac{y_i-\hat{m}(x_i)}{1-L_{ii}}\right)^2
                \]
              </p>
              <h1>Putting the Theory to Work</h1>
              <p>
              In practice, the calculation of \(X^\top X\) should often be
              avoided at all costs. Instead, we can use the \(QR\) factorization of
              \(X\) to solve the least-squares problem without ever touching
              \(X^\top X\). Because computational methods are always approximate,
              problems that are
              <a href="https://en.wikipedia.org/wiki/Condition_number">ill-conditioned</a>
              can amplify the error in
              \(X\), creating large innaccuracies in the solution \(\hat{\beta}\).
              </p>
              <div class="proof">
                <button onclick="hideElement('proof1')"> Show Proof </button>
                <p id="proof1" style="display: none;">
                  If \(X\) is full rank with \(n>p\),
                  $$
                   \begin{align} \kappa\left(X^\top X\right)
                   &= \left|\left|X^\top X\right|\right|_2\left|\left|\left(X^\top X\right)^{\dagger}\right|\right|_2  \\
                   &= \left|\left|X^\top X\right|\right|_2\left|\left|X^{\dagger} \left(X^{\dagger}\right)^{\top}\right|\right|_2  \\
                   &\leq ||X^\top||_2 ||X||_2 ||X^\dagger||_2 ||X^{{\dagger}^\top}||_2 \\
                   &= ||X||_2^2 ||X^\dagger||_2^2 \\
                   &= \kappa(X)^2
                   \end{align}
                  $$
                  Where the penultimate step uses the fact that \(||A^\top||_2 = ||A||_2\).
                  The "\(\leq\)" step comes from the submultiplicativity of
                  the matrix 2-norm.
                  \[
                    ||AB||_2 \leq ||A||_2||B||_2
                  \]
                </p>
              </div>
              <p>
              To stave off numerical innaccuracies arising from calculating
              \(X^\top X\), we can instead use the QR decomposition of \(X\) to
              derive the least squares solution \(\hat{\beta}\).
              </p>
              <div class="proof">
                <button onclick="hideElement('proof2')"> Show Proof </button>
                <p id="proof2" style="display: none;">
                  Let \(Q\tilde{R}=XP\) be the QR decomposition of X where
                  \(Q\) is an \(n\times n\) orthogonal matrix,
                  \(R\) is an \(n\times n\) upper triangular matrix, and
                  \(P\) is a permutation matrix so that
                  \[
                    Q\tilde{R}
                    = Q \begin{bmatrix} R \\ 0 \end{bmatrix}
                    = XP
                  \]
                  If \(X\) is full-rank, then \(R\) has full rank and is
                  thus invertible. Since \(Q^\top Q=I\), for any matrix \(A\)
                  we get
                  \[
                    ||QA||_2
                    = \sqrt{\langle QA, QA\rangle}
                    = \sqrt{\langle Q^\top QA, A\rangle}
                    = \sqrt{\langle A, A\rangle}
                    = ||A||_2^2
                  \]
                  This is called the unitarily invariant property of the
                  induced operator norm. Without loss of generality,
                  assume \(P=I\). Using the properties above we can write
                  $$
                    \begin{align}
                      ||X\beta - y||_2^2
                      &= ||Q^\top(X\beta-y)||_2^2\\
                      &= ||Q^\top(Q\tilde{R}\beta - y)||_2^2 \\
                      &= \left|\left|\begin{bmatrix} R \\ 0 \end{bmatrix}\beta - Q^\top y\right|\right|_2^2
                    \end{align}
                  $$
                  Writing
                  \[
                    Q^\top y = \begin{bmatrix} Q_1^\top y\\ Q_2^\top y \end{bmatrix}
                  \]
                  We can express the equation above as
                  \[
                    \left|\left|\begin{bmatrix} R \\ 0 \end{bmatrix}\beta - Q^\top y\right|\right|_2^2
                    = \left|\left|\begin{bmatrix} R\beta \\ 0 \end{bmatrix}
                     - \begin{bmatrix} Q_1^\top y\\ Q_2^\top y \end{bmatrix}\right|\right|_2^2
                     = \left|\left|\begin{bmatrix} R\beta - Q_1^\top y\\ - Q_2^\top y \end{bmatrix}\right|\right|_2^2
                    = || R\beta - Q_1^\top y||_2^2 + ||Q_2^\top y||_2^2
                  \]
                  Which means that the original least-squares problem can
                  be rewritten as follows:
                  $$
                  \begin{align}
                    \hat{\beta}
                    &= \arg \min_{\beta}||X\beta - y||_2^2\\
                    &= \arg \min_{\beta}|| R\beta - Q_1^\top y||_2^2 + ||Q_2^\top y||_2^2\\
                    &= \arg \min_{\beta}|| R\beta - Q_1^\top y||_2^2
                    \end{align}
                  $$
                </p>
              </div>
              <p>
              </p>
              <h3> Linear Regression </h3>
              <pre><code class="cpp">
                Rcpp::List fastols(arma::mat& X, arma::vec& y, arma::vec& w) {
                  // Solve OLS using fast QR decomposition
                  arma::mat Q, R;
                  arma::qr_econ(Q, R, X);
                  arma::vec beta = solve(R, (Q.t()*y));
                  // Find diagonal of hat matrix given the Q of the QR factorization above
                  arma::vec hat = sum(Q%Q.t(),1);
                  // Find LOO prediction error
                  arma::vec fittedy = X*beta;
                  arma::vec pred_err = (y - fittedy) / (1 - hat);
                  List listout = List::create(Named("beta")          = beta,
                                              Named("hatdiag")       = hat,
                                              Named("loo_pred_err")  = pred_err,
                                              Named("fitted.values") = fittedy);
                  return listout;
                }
              </code></pre>
              <h3> Weighted Linear Regression </h3>
              <pre><code class="cpp">
                Rcpp::List fastwls(arma::mat& X, arma::vec& y, arma::vec& w) {
                  // Solve OLS using fast QR decomposition
                  arma::mat Q, R;
                  arma::qr_econ(Q, R, X.each_col() % sqrt(w));
                  arma::vec beta = solve(R, (Q.t()*(y % sqrt(w))));
                  // Find diagonal of hat matrix given the Q of the QR factorization above
                  arma::mat Q1 = Q.each_col() / sqrt(w);
                  arma::mat Q2 = Q.each_col() % sqrt(w);
                  arma::vec hat = sum(Q1%Q2,1);
                  // Find LOO prediction error
                  arma::vec fittedy = X*beta;
                  arma::vec pred_err = (y - fittedy) / (1 - hat);
                  List listout = List::create(Named("beta")          = beta,
                                              Named("hatdiag")       = hat,
                                              Named("loo_pred_err")  = pred_err,
                                              Named("fitted.values") = fittedy);
                  return listout;
                }
              </code></pre>
              <h3> Local Linear Regression </h3>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="https://github.com/harveybarnhard">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://strava.com/athletes/16562005">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-strava fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted"></p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="../vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="../js/jqBootstrapValidation.js"></script>
    <script src="../js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="../js/clean-blog.min.js"></script>

    <!-- Button to show and hide elements -->
    <script>
    function hideElement(id) {
      var x = document.getElementById(id);
      if (x.style.display === "none") {
        x.style.display = "block";
      } else {
        x.style.display = "none";
      }
      x.scrollTop = x.scrollHeight;
    }
  </script>


</body>

</html>
